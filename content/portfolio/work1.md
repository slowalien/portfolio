---
date: "2022-10-05"
draft: false
image: img/portfolio/youtubelogo.jpg
showonlyimage: false
title: YouTubers' Interactions with Algorithmic Decisions
weight: 1
---

YouTubers felt confused and unfair about algorithmic decisions they received, and these decisions heavily impacted their performance metrics such as viewership, audience engagement, and ad income. This project provides **translatable design considerations** for algorithmic systems on creator/digital streaming platforms. 

<!--more-->

#### Project Information

> **Project leader** from October 2020 to January 2021


> **Methods**: Interviewed 28 YouTubers who are in the YouTube Partner Program and had experienced moderation.

#### Problem Statement

Content creators like YouTubers nowadays could be a profitable job for many people who aim to earn money (e.g., advertising income from YouTube or Creator Fund from TikTok) from platforms. For example, YouTube decides ad income from the viewing times and viewer engagement rates of videos, as the picture shown below.

But not all video content is advertiser-friendly or acceptable to communities. When YouTube deems a YouTuber’s video as unacceptable, YouTube will demonetize (i.e., issuing “limited ads” or “no ads”) a YouTuber’s videos or channels, eventually denying them from earning more future ad revenue through placing limited or no ads on the videos.

As platform like YouTube uses various algorithms (e.g., machine learning) to implement content moderation, little attention has been paid to how users interact with algorithmic moderation and their post-hoc experience. Especially for the users perform profitable content creation, few studies have understand how they receive, perceive, and react to algorithmic content moderation. This study aims to approach this research gap in the context of algorithmic moderation on YouTube. We ask: **How do YouTubers interact with algorithmic moderation on YouTube?**

#### Findings

![Perceiving Fairness of Algorithms][1]

![Encountering the Opacity of Algorithms][2]

#### Design Considerations
> **Transparency** of algorithmic decision-making process such as disclosing whether YouTuber’s videos are invisible under ‘restricted mode,’ on Creator Studio dashboard.

>Informing creators of **how moderation decision affects performance metrics** such as income and visibility.

>**Creators’ voice** should be further valued by algorithmic assemblage of moderation decision-making (e.g., self-certification tool).


[1]: img/portfolio/fairnessfinding.png

[2]: img/portfolio/opacity.png

